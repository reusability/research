{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This Notebook Contains Code that Tests the XGBoost Algorithm to find the best hyperparameters and tests feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This code is taken from https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/ and adapted to our needs... It is a comprehensive guide and is very useful to our cause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            1.0.0\n",
       "1              0.7\n",
       "2           2.5.23\n",
       "3           2.5.23\n",
       "4           2.4.20\n",
       "          ...     \n",
       "238    1.1.0.Final\n",
       "239           1.58\n",
       "240           1.13\n",
       "241          2.6.1\n",
       "242        1.4.3-1\n",
       "Name: release, Length: 243, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import libraries:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import metrics   #Additional scklearn functions\n",
    "from sklearn.model_selection import GridSearchCV  #Perforing grid search\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4\n",
    "\n",
    "train = pd.read_csv('./data/aggregate_201007.csv')\n",
    "target = 'reuse'\n",
    "IDcol = 'project'\n",
    "train.dropna()\n",
    "train.pop('maven_release')\n",
    "train.pop('release')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This function is used to fit the model while using cross validation as well, could be used later on for different models, however as of now it is exclusice to XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelfit(alg, dtrain, predictors,useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(dtrain[predictors].values, label=dtrain[target].values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='mlogloss', early_stopping_rounds=early_stopping_rounds)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain[predictors], dtrain[target],eval_metric='mlogloss')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    print (\"\\nModel Report\")\n",
    "    print (\"Accuracy : %.4g\" % metrics.accuracy_score(dtrain[target].values, dtrain_predictions))\n",
    "    print(alg)                \n",
    "    feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n",
    "    feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tuning tree based parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    if x['maven_reuse'] < 42: return 0\n",
    "    elif x['maven_reuse'] < 106 and x['maven_reuse']>=42: return 1\n",
    "    else: return 2\n",
    "\n",
    "train['reuse'] = train.apply(f, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project</th>\n",
       "      <th>maven_reuse</th>\n",
       "      <th>class_count</th>\n",
       "      <th>cbo_sum</th>\n",
       "      <th>cbo_average</th>\n",
       "      <th>cbo_stdev</th>\n",
       "      <th>cbo_median</th>\n",
       "      <th>cbo_min</th>\n",
       "      <th>cbo_max</th>\n",
       "      <th>nosi_sum</th>\n",
       "      <th>...</th>\n",
       "      <th>wmc_median</th>\n",
       "      <th>wmc_min</th>\n",
       "      <th>wmc_max</th>\n",
       "      <th>mathOperationsQty_sum</th>\n",
       "      <th>mathOperationsQty_average</th>\n",
       "      <th>mathOperationsQty_stdev</th>\n",
       "      <th>mathOperationsQty_median</th>\n",
       "      <th>mathOperationsQty_min</th>\n",
       "      <th>mathOperationsQty_max</th>\n",
       "      <th>reuse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aalto-xml</td>\n",
       "      <td>23.0</td>\n",
       "      <td>158</td>\n",
       "      <td>962.0</td>\n",
       "      <td>6.088608</td>\n",
       "      <td>6.154466</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1135.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1163.0</td>\n",
       "      <td>1660.0</td>\n",
       "      <td>10.506329</td>\n",
       "      <td>29.268523</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>airline</td>\n",
       "      <td>48.0</td>\n",
       "      <td>135</td>\n",
       "      <td>552.0</td>\n",
       "      <td>4.088889</td>\n",
       "      <td>4.931572</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>1.976982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>akka-actor</td>\n",
       "      <td>208.0</td>\n",
       "      <td>2965</td>\n",
       "      <td>17280.0</td>\n",
       "      <td>5.827993</td>\n",
       "      <td>7.032081</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>6752.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>630.0</td>\n",
       "      <td>1348.0</td>\n",
       "      <td>0.454637</td>\n",
       "      <td>4.703745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>akka-slf4j</td>\n",
       "      <td>135.0</td>\n",
       "      <td>2965</td>\n",
       "      <td>17280.0</td>\n",
       "      <td>5.827993</td>\n",
       "      <td>7.032081</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>6752.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>630.0</td>\n",
       "      <td>1348.0</td>\n",
       "      <td>0.454637</td>\n",
       "      <td>4.703745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>akka-testkit</td>\n",
       "      <td>258.0</td>\n",
       "      <td>2338</td>\n",
       "      <td>14078.0</td>\n",
       "      <td>6.049850</td>\n",
       "      <td>7.039021</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>5558.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>359.0</td>\n",
       "      <td>955.0</td>\n",
       "      <td>0.410400</td>\n",
       "      <td>2.490832</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 268 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        project  maven_reuse  class_count  cbo_sum  cbo_average  cbo_stdev  \\\n",
       "0     aalto-xml         23.0          158    962.0     6.088608   6.154466   \n",
       "1       airline         48.0          135    552.0     4.088889   4.931572   \n",
       "2    akka-actor        208.0         2965  17280.0     5.827993   7.032081   \n",
       "3    akka-slf4j        135.0         2965  17280.0     5.827993   7.032081   \n",
       "4  akka-testkit        258.0         2338  14078.0     6.049850   7.039021   \n",
       "\n",
       "   cbo_median  cbo_min  cbo_max  nosi_sum  ...  wmc_median  wmc_min  wmc_max  \\\n",
       "0         4.0      0.0     35.0    1135.0  ...        14.5      0.0   1163.0   \n",
       "1         3.0      0.0     29.0     224.0  ...         1.0      0.0     52.0   \n",
       "2         3.0      0.0     39.0    6752.0  ...         2.0      0.0    630.0   \n",
       "3         3.0      0.0     39.0    6752.0  ...         2.0      0.0    630.0   \n",
       "4         3.0      0.0     38.0    5558.0  ...         2.0      0.0    359.0   \n",
       "\n",
       "   mathOperationsQty_sum  mathOperationsQty_average  mathOperationsQty_stdev  \\\n",
       "0                 1660.0                  10.506329                29.268523   \n",
       "1                   69.0                   0.511111                 1.976982   \n",
       "2                 1348.0                   0.454637                 4.703745   \n",
       "3                 1348.0                   0.454637                 4.703745   \n",
       "4                  955.0                   0.410400                 2.490832   \n",
       "\n",
       "   mathOperationsQty_median  mathOperationsQty_min  mathOperationsQty_max  \\\n",
       "0                       2.0                    0.0                  231.0   \n",
       "1                       0.0                    0.0                   14.0   \n",
       "2                       0.0                    0.0                  215.0   \n",
       "3                       0.0                    0.0                  215.0   \n",
       "4                       0.0                    0.0                   67.0   \n",
       "\n",
       "   reuse  \n",
       "0      0  \n",
       "1      1  \n",
       "2      2  \n",
       "3      2  \n",
       "4      2  \n",
       "\n",
       "[5 rows x 268 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train.reuse.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        23.0\n",
       "1        48.0\n",
       "2       208.0\n",
       "3       135.0\n",
       "4       258.0\n",
       "        ...  \n",
       "238    2085.0\n",
       "239     138.0\n",
       "240      21.0\n",
       "241      10.0\n",
       "242      18.0\n",
       "Name: maven_reuse, Length: 243, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.pop('maven_reuse')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 243 entries, 0 to 242\n",
      "Columns: 267 entries, project to reuse\n",
      "dtypes: float64(264), int64(2), object(1)\n",
      "memory usage: 507.0+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "243"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['reuse'].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64395"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Choose all predictors except target & IDcols\n",
    "predictors = [x for x in train.columns if x not in [target, IDcol]]\n",
    "\n",
    "train[predictors].size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_count</th>\n",
       "      <th>cbo_sum</th>\n",
       "      <th>cbo_average</th>\n",
       "      <th>cbo_stdev</th>\n",
       "      <th>cbo_median</th>\n",
       "      <th>cbo_min</th>\n",
       "      <th>cbo_max</th>\n",
       "      <th>nosi_sum</th>\n",
       "      <th>nosi_average</th>\n",
       "      <th>nosi_stdev</th>\n",
       "      <th>...</th>\n",
       "      <th>wmc_stdev</th>\n",
       "      <th>wmc_median</th>\n",
       "      <th>wmc_min</th>\n",
       "      <th>wmc_max</th>\n",
       "      <th>mathOperationsQty_sum</th>\n",
       "      <th>mathOperationsQty_average</th>\n",
       "      <th>mathOperationsQty_stdev</th>\n",
       "      <th>mathOperationsQty_median</th>\n",
       "      <th>mathOperationsQty_min</th>\n",
       "      <th>mathOperationsQty_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>158</td>\n",
       "      <td>962.0</td>\n",
       "      <td>6.088608</td>\n",
       "      <td>6.154466</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1135.0</td>\n",
       "      <td>7.183544</td>\n",
       "      <td>29.247209</td>\n",
       "      <td>...</td>\n",
       "      <td>158.906812</td>\n",
       "      <td>14.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1163.0</td>\n",
       "      <td>1660.0</td>\n",
       "      <td>10.506329</td>\n",
       "      <td>29.268523</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>231.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>135</td>\n",
       "      <td>552.0</td>\n",
       "      <td>4.088889</td>\n",
       "      <td>4.931572</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>1.659259</td>\n",
       "      <td>5.519522</td>\n",
       "      <td>...</td>\n",
       "      <td>10.006615</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>1.976982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2965</td>\n",
       "      <td>17280.0</td>\n",
       "      <td>5.827993</td>\n",
       "      <td>7.032081</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>6752.0</td>\n",
       "      <td>2.277234</td>\n",
       "      <td>5.673473</td>\n",
       "      <td>...</td>\n",
       "      <td>31.052490</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>630.0</td>\n",
       "      <td>1348.0</td>\n",
       "      <td>0.454637</td>\n",
       "      <td>4.703745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>215.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2965</td>\n",
       "      <td>17280.0</td>\n",
       "      <td>5.827993</td>\n",
       "      <td>7.032081</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>6752.0</td>\n",
       "      <td>2.277234</td>\n",
       "      <td>5.673473</td>\n",
       "      <td>...</td>\n",
       "      <td>31.052490</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>630.0</td>\n",
       "      <td>1348.0</td>\n",
       "      <td>0.454637</td>\n",
       "      <td>4.703745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>215.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2338</td>\n",
       "      <td>14078.0</td>\n",
       "      <td>6.049850</td>\n",
       "      <td>7.039021</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>5558.0</td>\n",
       "      <td>2.388483</td>\n",
       "      <td>5.622734</td>\n",
       "      <td>...</td>\n",
       "      <td>29.221798</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>359.0</td>\n",
       "      <td>955.0</td>\n",
       "      <td>0.410400</td>\n",
       "      <td>2.490832</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 265 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   class_count  cbo_sum  cbo_average  cbo_stdev  cbo_median  cbo_min  cbo_max  \\\n",
       "0          158    962.0     6.088608   6.154466         4.0      0.0     35.0   \n",
       "1          135    552.0     4.088889   4.931572         3.0      0.0     29.0   \n",
       "2         2965  17280.0     5.827993   7.032081         3.0      0.0     39.0   \n",
       "3         2965  17280.0     5.827993   7.032081         3.0      0.0     39.0   \n",
       "4         2338  14078.0     6.049850   7.039021         3.0      0.0     38.0   \n",
       "\n",
       "   nosi_sum  nosi_average  nosi_stdev  ...   wmc_stdev  wmc_median  wmc_min  \\\n",
       "0    1135.0      7.183544   29.247209  ...  158.906812        14.5      0.0   \n",
       "1     224.0      1.659259    5.519522  ...   10.006615         1.0      0.0   \n",
       "2    6752.0      2.277234    5.673473  ...   31.052490         2.0      0.0   \n",
       "3    6752.0      2.277234    5.673473  ...   31.052490         2.0      0.0   \n",
       "4    5558.0      2.388483    5.622734  ...   29.221798         2.0      0.0   \n",
       "\n",
       "   wmc_max  mathOperationsQty_sum  mathOperationsQty_average  \\\n",
       "0   1163.0                 1660.0                  10.506329   \n",
       "1     52.0                   69.0                   0.511111   \n",
       "2    630.0                 1348.0                   0.454637   \n",
       "3    630.0                 1348.0                   0.454637   \n",
       "4    359.0                  955.0                   0.410400   \n",
       "\n",
       "   mathOperationsQty_stdev  mathOperationsQty_median  mathOperationsQty_min  \\\n",
       "0                29.268523                       2.0                    0.0   \n",
       "1                 1.976982                       0.0                    0.0   \n",
       "2                 4.703745                       0.0                    0.0   \n",
       "3                 4.703745                       0.0                    0.0   \n",
       "4                 2.490832                       0.0                    0.0   \n",
       "\n",
       "   mathOperationsQty_max  \n",
       "0                  231.0  \n",
       "1                   14.0  \n",
       "2                  215.0  \n",
       "3                  215.0  \n",
       "4                   67.0  \n",
       "\n",
       "[5 rows x 265 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[predictors].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(243,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[target].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(243, 265)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[predictors].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:44:02] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[07:44:02] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[07:44:02] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[07:44:02] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[07:44:02] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[07:44:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "\n",
      "Model Report\n",
      "Accuracy : 0.9012\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=0.8, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=16, n_jobs=4, nthread=4, num_class=3,\n",
      "              num_parallel_tree=1, objective='multi:softprob', random_state=27,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=27,\n",
      "              subsample=0.8, tree_method='exact', validate_parameters=1,\n",
      "              verbosity=None)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-f77c12373a62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m  \u001b[0mscale_pos_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m  seed=27)\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmodelfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-40-2557f9d81a0d>\u001b[0m in \u001b[0;36mmodelfit\u001b[0;34m(alg, dtrain, predictors, useTrainCV, cv_folds, early_stopping_rounds)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy : %.4g\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mfeat_imp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbooster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_fscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mfeat_imp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bar'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Feature Importances'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Feature Importance Score'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "xgb1 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'multi:softprob',\n",
    " num_class = 3,\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "modelfit(xgb1, train, predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tuning max depth and min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/model_selection/_search.py:849: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:48:16] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'max_depth': 7, 'min_child_weight': 5},\n",
       " -1.263115080072367,\n",
       " {'mean_fit_time': array([1.04342966, 0.96900659, 0.99141445, 1.36430459, 1.17474437,\n",
       "         1.19740953, 1.52388473, 1.26495895, 1.15464754, 1.52351556,\n",
       "         1.31278839, 1.13266306]),\n",
       "  'std_fit_time': array([0.02319718, 0.02600045, 0.03284106, 0.09618033, 0.04167889,\n",
       "         0.11852837, 0.03288633, 0.07708528, 0.12651061, 0.01918688,\n",
       "         0.05433089, 0.04929654]),\n",
       "  'mean_score_time': array([0.01093163, 0.01064463, 0.01095157, 0.01134963, 0.01102886,\n",
       "         0.01121202, 0.01139708, 0.01114941, 0.01193242, 0.0116292 ,\n",
       "         0.01153121, 0.01044803]),\n",
       "  'std_score_time': array([0.00050076, 0.00030019, 0.00021023, 0.00040451, 0.0002142 ,\n",
       "         0.00057005, 0.00065886, 0.00082329, 0.00021914, 0.00037513,\n",
       "         0.00035261, 0.00084086]),\n",
       "  'param_max_depth': masked_array(data=[3, 3, 3, 5, 5, 5, 7, 7, 7, 9, 9, 9],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_min_child_weight': masked_array(data=[1, 3, 5, 1, 3, 5, 1, 3, 5, 1, 3, 5],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'max_depth': 3, 'min_child_weight': 1},\n",
       "   {'max_depth': 3, 'min_child_weight': 3},\n",
       "   {'max_depth': 3, 'min_child_weight': 5},\n",
       "   {'max_depth': 5, 'min_child_weight': 1},\n",
       "   {'max_depth': 5, 'min_child_weight': 3},\n",
       "   {'max_depth': 5, 'min_child_weight': 5},\n",
       "   {'max_depth': 7, 'min_child_weight': 1},\n",
       "   {'max_depth': 7, 'min_child_weight': 3},\n",
       "   {'max_depth': 7, 'min_child_weight': 5},\n",
       "   {'max_depth': 9, 'min_child_weight': 1},\n",
       "   {'max_depth': 9, 'min_child_weight': 3},\n",
       "   {'max_depth': 9, 'min_child_weight': 5}],\n",
       "  'split0_test_score': array([-1.4133154 , -1.32210824, -1.32216634, -1.44663189, -1.40747592,\n",
       "         -1.36359144, -1.42493146, -1.43084511, -1.3426466 , -1.43125235,\n",
       "         -1.41539871, -1.3426466 ]),\n",
       "  'split1_test_score': array([-1.29221677, -1.24866107, -1.22577332, -1.32358447, -1.22771187,\n",
       "         -1.17663798, -1.33196245, -1.25912601, -1.19414195, -1.34339557,\n",
       "         -1.25912601, -1.19414195]),\n",
       "  'split2_test_score': array([-1.23935601, -1.2301493 , -1.20502225, -1.33046406, -1.19826056,\n",
       "         -1.19389911, -1.26016399, -1.2804188 , -1.24487385, -1.24968253,\n",
       "         -1.29465735, -1.24487385]),\n",
       "  'split3_test_score': array([-1.61578956, -1.64063812, -1.48503536, -1.67826454, -1.57901433,\n",
       "         -1.50856769, -1.64851493, -1.62891516, -1.50183266, -1.6605797 ,\n",
       "         -1.60489571, -1.50183266]),\n",
       "  'split4_test_score': array([-1.13064587, -1.11675801, -1.09017435, -1.22609474, -1.12929652,\n",
       "         -1.09309853, -1.2265844 , -1.11575305, -1.03208033, -1.19766251,\n",
       "         -1.13880152, -1.03208033]),\n",
       "  'mean_test_score': array([-1.33826472, -1.31166295, -1.26563432, -1.40100794, -1.30835184,\n",
       "         -1.26715895, -1.37843145, -1.34301162, -1.26311508, -1.37651453,\n",
       "         -1.34257586, -1.26311508]),\n",
       "  'std_test_score': array([0.16592864, 0.177164  , 0.13219804, 0.15525349, 0.16356495,\n",
       "         0.14928864, 0.15120279, 0.17438846, 0.15606309, 0.16300952,\n",
       "         0.15804994, 0.15606309]),\n",
       "  'rank_test_score': array([ 7,  6,  3, 12,  5,  4, 11,  9,  1, 10,  8,  1], dtype=int32)})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test1 = {\n",
    " 'max_depth':range(3,10,2),\n",
    " 'min_child_weight':range(1,6,2)\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=5,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'multi:softprob',num_class=3, nthread=4, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test1, scoring='neg_log_loss',n_jobs=4,iid=False, cv=5)\n",
    "gsearch1.fit(train[predictors],train[target])\n",
    "gsearch1.best_params_, gsearch1.best_score_, gsearch1.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tuning Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test2 = {\n",
    " 'max_depth':[4,5,6],\n",
    " 'min_child_weight':[4,5,6]\n",
    "}\n",
    "gsearch2 = GridSearchCV(estimator = XGBClassifier( learning_rate=0.1, n_estimators=140, max_depth=5,\n",
    " min_child_weight=2, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test2, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch2.fit(train[predictors],train[target])\n",
    "gsearch2.grid_scores_, gsearch2.best_params_, gsearch2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test2b = {\n",
    " 'min_child_weight':[6,8,10,12]\n",
    "}\n",
    "gsearch2b = GridSearchCV(estimator = XGBClassifier( learning_rate=0.1, n_estimators=140, max_depth=4,\n",
    " min_child_weight=2, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test2b, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch2b.fit(train[predictors],train[target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tune subsample and colsample_bytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelfit(gsearch3.best_estimator_, train, predictors)\n",
    "gsearch2b.grid_scores_, gsearch2b.best_params_, gsearch2b.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test3 = {\n",
    " 'gamma':[i/10.0 for i in range(0,5)]\n",
    "}\n",
    "gsearch3 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=4,\n",
    " min_child_weight=6, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test3, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch3.fit(train[predictors],train[target])\n",
    "gsearch3.grid_scores_, gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tunin regularization parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb2 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=4,\n",
    " min_child_weight=6,\n",
    " gamma=,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "modelfit(xgb2, train, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test4 = {\n",
    " 'subsample':[i/10.0 for i in range(6,10)],\n",
    " 'colsample_bytree':[i/10.0 for i in range(6,10)]\n",
    "}\n",
    "gsearch4 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=177, max_depth=4,\n",
    " min_child_weight=6, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test4, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch4.fit(train[predictors],train[target])\n",
    "gsearch4.grid_scores_, gsearch4.best_params_, gsearch4.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test5 = {\n",
    " 'subsample':[i/100.0 for i in range(75,90,5)],\n",
    " 'colsample_bytree':[i/100.0 for i in range(75,90,5)]\n",
    "}\n",
    "gsearch5 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=177, max_depth=4,\n",
    " min_child_weight=6, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test5, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch5.fit(train[predictors],train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test6 = {\n",
    " 'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]\n",
    "}\n",
    "gsearch6 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=177, max_depth=4,\n",
    " min_child_weight=6, gamma=0.1, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test6, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch6.fit(train[predictors],train[target])\n",
    "gsearch6.grid_scores_, gsearch6.best_params_, gsearch6.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test7 = {\n",
    " 'reg_alpha':[0, 0.001, 0.005, 0.01, 0.05]\n",
    "}\n",
    "gsearch7 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=177, max_depth=4,\n",
    " min_child_weight=6, gamma=0.1, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test7, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch7.fit(train[predictors],train[target])\n",
    "gsearch7.grid_scores_, gsearch7.best_params_, gsearch7.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgb3 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=4,\n",
    " min_child_weight=6,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " reg_alpha=0.005,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "modelfit(xgb3, train, predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reducing learning rate and increasing number of trees (be careful here because this may lead to overtraining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb4 = XGBClassifier(\n",
    " learning_rate =0.01,\n",
    " n_estimators=5000,\n",
    " max_depth=4,\n",
    " min_child_weight=6,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " reg_alpha=0.005,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "modelfit(xgb4, train, predictors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "language": "python",
   "name": "python37364bit09fa43b68a324603b1bde449d329c7d5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
