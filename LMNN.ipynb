{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original feature shape: (216, 265)\n",
      "Transformed feature shape: (216, 209)\n"
     ]
    }
   ],
   "source": [
    "# import local modules.\n",
    "from model.k_nearest_neigbors import KNearestNeighbors\n",
    "from model.lmnn import LMNN\n",
    "\n",
    "from utils import data_loader, pre_training_analysis_tools\n",
    "\n",
    "\n",
    "data = data_loader.load_real_dataset(sqaured=False, remove_multicollinearity=False)\n",
    "output_xy = pre_training_analysis_tools.variance_threshold(data['train_x'],data['train_y'])\n",
    "split_xy = pre_training_analysis_tools.split_dataxy(output_xy)\n",
    "x = split_xy['train_x']\n",
    "y = split_xy['train_y']\n",
    "\n",
    "from skfeature.function.statistical_based import CFS\n",
    "score = CFS.cfs(x.to_numpy() , y.to_numpy())    \n",
    "x = x.iloc[:, [32, 131,  33,  39, 174,  26, 132, 144,   9,  10,  15,  20]]\n",
    "\n",
    "data_xy = pre_training_analysis_tools.join_dataxy(x, y)\n",
    "data = pre_training_analysis_tools.generate_train_test_xy(data_xy)\n",
    "\n",
    "\n",
    "data_x = data['train_x']\n",
    "data_y =     data['train_y']\n",
    "test_x =     data['test_x']\n",
    "test_y =   data['test_y']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 of Bayesian Optimisation\n",
      "Trying n_neighbors(lmnn)=8\tn_neighbors(knn)=11\tn_components=3\tmax_iter=85 ...\n",
      "\n",
      "Evaluating the found transformation on validation set of size 23...\n",
      "Validation error=0.5217\n",
      "\n",
      "Iteration 2 of Bayesian Optimisation\n",
      "Trying n_neighbors(lmnn)=3\tn_neighbors(knn)=4\tn_components=10\tmax_iter=56 ...\n",
      "\n",
      "Evaluating the found transformation on validation set of size 23...\n",
      "Validation error=0.5652\n",
      "\n",
      "Iteration 3 of Bayesian Optimisation\n",
      "Trying n_neighbors(lmnn)=1\tn_neighbors(knn)=13\tn_components=4\tmax_iter=71 ...\n",
      "\n",
      "Evaluating the found transformation on validation set of size 23...\n",
      "Validation error=0.4783\n",
      "\n",
      "Iteration 4 of Bayesian Optimisation\n",
      "Trying n_neighbors(lmnn)=9\tn_neighbors(knn)=12\tn_components=12\tmax_iter=53 ...\n",
      "\n",
      "Evaluating the found transformation on validation set of size 23...\n",
      "Validation error=0.6087\n",
      "\n",
      "Iteration 5 of Bayesian Optimisation\n",
      "Trying n_neighbors(lmnn)=12\tn_neighbors(knn)=1\tn_components=8\tmax_iter=159 ...\n",
      "\n",
      "Evaluating the found transformation on validation set of size 23...\n",
      "Validation error=0.7391\n",
      "\n",
      "Iteration 6 of Bayesian Optimisation\n",
      "Trying n_neighbors(lmnn)=4\tn_neighbors(knn)=9\tn_components=4\tmax_iter=50 ...\n",
      "\n",
      "Evaluating the found transformation on validation set of size 23...\n",
      "Validation error=0.6087\n",
      "\n",
      "Iteration 7 of Bayesian Optimisation\n",
      "Trying n_neighbors(lmnn)=10\tn_neighbors(knn)=9\tn_components=8\tmax_iter=41 ...\n",
      "\n",
      "Evaluating the found transformation on validation set of size 23...\n",
      "Validation error=0.6522\n",
      "\n",
      "Iteration 8 of Bayesian Optimisation\n",
      "Trying n_neighbors(lmnn)=1\tn_neighbors(knn)=3\tn_components=4\tmax_iter=84 ...\n",
      "\n",
      "Evaluating the found transformation on validation set of size 23...\n",
      "Validation error=0.4783\n",
      "\n",
      "Iteration 9 of Bayesian Optimisation\n",
      "Trying n_neighbors(lmnn)=5\tn_neighbors(knn)=5\tn_components=9\tmax_iter=45 ...\n",
      "\n",
      "Evaluating the found transformation on validation set of size 23...\n",
      "Validation error=0.6087\n",
      "\n",
      "Iteration 10 of Bayesian Optimisation\n",
      "Trying n_neighbors(lmnn)=11\tn_neighbors(knn)=11\tn_components=7\tmax_iter=164 ...\n",
      "\n",
      "Evaluating the found transformation on validation set of size 23...\n",
      "Validation error=0.6522\n",
      "\n",
      "Iteration 11 of Bayesian Optimisation\n",
      "Trying n_neighbors(lmnn)=13\tn_neighbors(knn)=1\tn_components=8\tmax_iter=90 ...\n",
      "\n",
      "Evaluating the found transformation on validation set of size 23...\n",
      "Validation error=0.6957\n",
      "\n",
      "Iteration 12 of Bayesian Optimisation\n",
      "Trying n_neighbors(lmnn)=8\tn_neighbors(knn)=13\tn_components=3\tmax_iter=54 ...\n",
      "\n",
      "Evaluating the found transformation on validation set of size 23...\n",
      "Validation error=0.5217\n",
      "\n",
      "Iteration 13 of Bayesian Optimisation\n",
      "Trying n_neighbors(lmnn)=14\tn_neighbors(knn)=5\tn_components=4\tmax_iter=49 ...\n",
      "\n",
      "Evaluating the found transformation on validation set of size 23...\n",
      "Validation error=0.7826\n",
      "\n",
      "Iteration 14 of Bayesian Optimisation\n",
      "Trying n_neighbors(lmnn)=3\tn_neighbors(knn)=13\tn_components=11\tmax_iter=152 ...\n",
      "\n",
      "Evaluating the found transformation on validation set of size 23...\n",
      "Validation error=0.5652\n",
      "\n",
      "Iteration 15 of Bayesian Optimisation\n",
      "Trying n_neighbors(lmnn)=2\tn_neighbors(knn)=7\tn_components=3\tmax_iter=194 ...\n",
      "\n",
      "Evaluating the found transformation on validation set of size 23...\n",
      "Validation error=0.6957\n",
      "\n",
      "Iteration 16 of Bayesian Optimisation\n",
      "Trying n_neighbors(lmnn)=7\tn_neighbors(knn)=7\tn_components=11\tmax_iter=74 ...\n",
      "\n",
      "Evaluating the found transformation on validation set of size 23...\n",
      "Validation error=0.4783\n",
      "\n",
      "Iteration 17 of Bayesian Optimisation\n",
      "Trying n_neighbors(lmnn)=9\tn_neighbors(knn)=5\tn_components=11\tmax_iter=78 ...\n",
      "\n",
      "Evaluating the found transformation on validation set of size 23...\n",
      "Validation error=0.6087\n",
      "\n",
      "[1.10602969e+00 1.26265241e+01 3.91842497e+00 7.01741537e+01\n",
      " 8.99658334e-01 3.24502599e+05]\n",
      "Best parameters: n_neighbors(lmnn)=1 n_neighbors(knn)=13 n_components=4 max_iter=71\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 13, 4, 71, 1.0, 324503)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## need to figue out how to use it first \n",
    "import numpy as np\n",
    "from argparse import Namespace\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from GPyOpt.methods import BayesianOptimization\n",
    "\n",
    "from pylmnn import LargeMarginNearestNeighbor\n",
    "\n",
    "\n",
    "def find_hyperparams(X_train, y_train, X_valid, y_valid, params=None, max_bopt_iter=1000):\n",
    "    \"\"\"Find the best hyperparameters for LMNN using Bayesian Optimisation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    X_train : array_like\n",
    "           An array of training samples with shape (n_samples, n_features).\n",
    "\n",
    "    y_train : array_like\n",
    "           An array of training labels with shape (n_samples,).\n",
    "\n",
    "    X_valid : array_like\n",
    "           An array of validation samples with shape (m_samples, n_features).\n",
    "\n",
    "    y_valid : array_like\n",
    "           An array of validation labels with shape (m_samples,).\n",
    "\n",
    "    params : dict\n",
    "             A dictionary of parameters to be passed to the LargeMarginNearestNeighbor classifier instance.\n",
    "\n",
    "    max_bopt_iter : int\n",
    "            Maximum number of parameter configurations to evaluate (Default value = 12).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple:\n",
    "        (int, int, int, int) The best hyperparameters found (n_neighbors, n_neighbors_predict, n_components, max_iter).\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    params = params or {}\n",
    "    unique_labels, class_sizes = np.unique(y_train, return_counts=True)\n",
    "    min_class_size = min(class_sizes)\n",
    "\n",
    "    # Setting parameters for Bayesian Global Optimization\n",
    "    args = Namespace()\n",
    "    args.min_neighbors = 1\n",
    "    args.max_neighbors = int(min(min_class_size - 1, 15))\n",
    "    args.min_iter = 10\n",
    "    args.max_iter = 200\n",
    "    args.min_components = min(X_train.shape[1], 2)\n",
    "    args.max_components = X_train.shape[1]\n",
    "\n",
    "    bopt_iter = 0\n",
    "\n",
    "    def optimize_clf(hyperparams):\n",
    "        \"\"\"The actual objective function with packing and unpacking of hyperparameters.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        hyperparams : array_like\n",
    "                 Vector of hyperparameters to evaluate.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            The validation error obtained.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        hyperparams = hyperparams[0]\n",
    "        n_neighbors = int(round(hyperparams[0]))\n",
    "        n_neighbors_predict = int(round(hyperparams[1]))\n",
    "        n_components = int(np.ceil(hyperparams[2]))\n",
    "        max_iter = int(np.ceil(hyperparams[3]))\n",
    "        weight_push_loss = float(np.ceil(hyperparams[4]))\n",
    "        max_impostors = int(np.ceil(hyperparams[5]))\n",
    "\n",
    "        nonlocal bopt_iter\n",
    "        bopt_iter += 1\n",
    "        print('Iteration {} of Bayesian Optimisation'.format(bopt_iter))\n",
    "        print('Trying n_neighbors(lmnn)={}\\tn_neighbors(knn)={}\\tn_components={}\\tmax_iter={} ...\\n'\n",
    "              .format(n_neighbors, n_neighbors_predict, n_components, max_iter, weight_push_loss,max_impostors))\n",
    "        lmnn = LargeMarginNearestNeighbor(n_neighbors, max_iter=max_iter, n_components=n_components, \n",
    "                                          weight_push_loss=weight_push_loss,max_impostors=max_impostors, **params)\n",
    "        lmnn.fit(X_train, y_train)\n",
    "        clf = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "        clf.fit(lmnn.transform(X_train), y_train)\n",
    "\n",
    "        print('Evaluating the found transformation on validation set of size {}...'.format(len(y_valid)))\n",
    "        val_err = 1. - clf.score(lmnn.transform(X_valid), y_valid)\n",
    "\n",
    "        print('Validation error={:2.4f}\\n'.format(val_err))\n",
    "        return val_err\n",
    "\n",
    "    # Parameters are discrete but treating them as continuous yields better parameters\n",
    "    domain = [{'name': 'n_neighbors', 'type': 'continuous', 'domain': (args.min_neighbors, args.max_neighbors)},\n",
    "              {'name': 'n_neighbors_predict', 'type': 'continuous', 'domain': (args.min_neighbors, args.max_neighbors)},\n",
    "              {'name': 'n_components', 'type': 'continuous', 'domain': (args.min_components, args.max_components)},\n",
    "              {'name': 'max_iter', 'type': 'continuous', 'domain': (args.min_iter, args.max_iter)},\n",
    "              {'name': 'weight_push_loss', 'type': 'continuous', 'domain': (0, 1)},\n",
    "              {'name': 'max_impostors', 'type': 'continuous', 'domain': (1, 1000000)}]\n",
    "    bo = BayesianOptimization(f=optimize_clf, domain=domain)\n",
    "    bo.run_optimization(max_iter=max_bopt_iter)\n",
    "\n",
    "    solution = bo.x_opt\n",
    "    print(solution)\n",
    "    best_n_neighbors = int(round(solution[0]))\n",
    "    best_n_neighbors_predict = int(round(solution[1]))\n",
    "    best_n_components = int(np.ceil(solution[2]))\n",
    "    best_max_iter = int(np.ceil(solution[3]))\n",
    "    best_weight_push_loss = float(np.ceil(solution[4]))\n",
    "    best_max_impostors = int(np.ceil(solution[5]))\n",
    "\n",
    "    print('Best parameters: n_neighbors(lmnn)={} n_neighbors(knn)={} n_components={} max_iter={}\\n'.\n",
    "          format(best_n_neighbors, best_n_neighbors_predict, best_n_components, best_max_iter, best_weight_push_loss, best_max_impostors))\n",
    "\n",
    "    return best_n_neighbors, best_n_neighbors_predict, best_n_components, best_max_iter, best_weight_push_loss, best_max_impostors\n",
    "\n",
    "#execute\n",
    "\n",
    "\n",
    "find_hyperparams(X_train=data_x, y_train=data_y, X_valid=test_x, y_valid=test_y, max_bopt_iter=12)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LMNN accuracy on test set of 23 points: 0.5217\n"
     ]
    }
   ],
   "source": [
    "from pylmnn import LargeMarginNearestNeighbor as LMNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Set up the hyperparameters\n",
    "# Instantiate the metric learner\n",
    "#lmnn = LMNN(n_neighbors=13, max_iter=63, n_components=2 )\n",
    "# adding make no difference: weight_push_loss=1.0\n",
    "# max_impostors=871159\n",
    "#lmnn = LMNN(n_neighbors=6, max_iter=80, n_components=6 )\n",
    "lmnn = LMNN(n_neighbors=10, max_iter=109, n_components=6 )\n",
    "\n",
    "\n",
    "#10, 5, 6, 109, 1.0, 646122\n",
    "\n",
    "# Train the metric learner\n",
    "lmnn.fit(data_x, data_y)\n",
    "\n",
    "# Fit the nearest neighbors classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "knn.fit(lmnn.transform(data_x), data_y)\n",
    "\n",
    "# Compute the k-nearest neighbor test accuracy after applying the learned transformation\n",
    "lmnn_acc = knn.score(lmnn.transform(test_x), test_y)\n",
    "print('LMNN accuracy on test set of {} points: {:.4f}'.format(test_x.shape[0], lmnn_acc))\n",
    "\n",
    "\n",
    "# 0.8 cor & new data set & cfs = 0.5179"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python37464bit7f1e84062742452e83d5ee685770f253"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
